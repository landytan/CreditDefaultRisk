{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-785da50e002b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m \u001b[0;31m# for making plots with seaborn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_notebook_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import numpy as np # fundamental package for scientific computing with Python\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import seaborn as sns # for making plots with seaborn\n",
    "color = sns.color_palette()\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import plotly.offline as offline\n",
    "offline.init_notebook_mode()\n",
    "# from plotly import tools\n",
    "# import plotly.tools as tls\n",
    "# import squarify\n",
    "# from mpl_toolkits.basemap import Basemap\n",
    "# from numpy import array\n",
    "# from matplotlib import cm\n",
    "\n",
    "# import cufflinks and offline mode\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "app_train=pd.read_csv('file:///F:/BaiduNetdiskDownload/信用风险数据集/application_train.csv')\n",
    "app_test = pd.read_csv('file:///F:/BaiduNetdiskDownload/信用风险数据集/application_test.csv')\n",
    "\n",
    "app_train.head() \n",
    "\n",
    "#定义缺失值检测函数\n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns\n",
    "\n",
    "missing_values = missing_values_table(app_train)\n",
    "missing_values.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(app_train['DAYS_BIRTH'] / -365).describe()\n",
    "(app_train['DAYS_EMPLOYED']/-365).describe()\n",
    "app_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');\n",
    "\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "(app_train['DAYS_EMPLOYED']/-365).plot.hist(title = 'Days Employment Histogram');\n",
    "plt.xlabel('Days Employment');\n",
    "\n",
    "#这一段是画图代码，无需弄懂\n",
    "def plot_stats(feature,label_rotation=False,horizontal_layout=True):\n",
    "    temp = app_train[feature].value_counts()\n",
    "    df1 = pd.DataFrame({feature: temp.index,'Number of contracts': temp.values})\n",
    "\n",
    "    # Calculate the percentage of target=1 per category value\n",
    "    cat_perc = app_train[[feature, 'TARGET']].groupby([feature],as_index=False).mean()\n",
    "    cat_perc.sort_values(by='TARGET', ascending=False, inplace=True)\n",
    "    \n",
    "    if(horizontal_layout):\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n",
    "    else:\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14))\n",
    "    sns.set_color_codes(\"pastel\")\n",
    "    s = sns.barplot(ax=ax1, x = feature, y=\"Number of contracts\",data=df1)\n",
    "    if(label_rotation):\n",
    "        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    \n",
    "    s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=cat_perc[feature], data=cat_perc)\n",
    "    if(label_rotation):\n",
    "        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    plt.ylabel('Percent of target with value 1 [%]', fontsize=10)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    plt.show();\n",
    "    \n",
    "def plot_distribution(var):\n",
    "    \n",
    "    i = 0\n",
    "    t1 = app_train.loc[app_train['TARGET'] != 0]\n",
    "    t0 = app_train.loc[app_train['TARGET'] == 0]\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2,2,figsize=(12,12))\n",
    "\n",
    "    for feature in var:\n",
    "        i += 1\n",
    "        plt.subplot(2,2,i)\n",
    "        sns.kdeplot(t1[feature], bw=0.5,label=\"TARGET = 1\")\n",
    "        sns.kdeplot(t0[feature], bw=0.5,label=\"TARGET = 0\")\n",
    "        plt.ylabel('Density plot', fontsize=12)\n",
    "        plt.xlabel(feature, fontsize=12)\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.show();\n",
    "\n",
    "    plt.figure(figsize = (10, 8))\n",
    "\n",
    "# KDE plot of loans that were repaid on time\n",
    "sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / -365, label = 'target == 0')\n",
    "\n",
    "# KDE plot of loans which were not repaid on time\n",
    "sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / -365, label = 'target == 1')\n",
    "\n",
    "# Labeling of plot\n",
    "plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');\n",
    "\n",
    "age_data = app_train[['TARGET', 'DAYS_BIRTH']]\n",
    "age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / -365\n",
    "\n",
    "# Bin the age data\n",
    "age_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins = np.linspace(20, 70, num = 11))\n",
    "age_groups  = age_data.groupby('YEARS_BINNED').mean()\n",
    "plt.figure(figsize = (8, 8))\n",
    "\n",
    "# Graph the age bins and the average of the target as a bar plot\n",
    "plt.bar(age_groups.index.astype(str), 100 * age_groups['TARGET'])\n",
    "\n",
    "# Plot labeling\n",
    "plt.xticks(rotation = 75); plt.xlabel('Age Group (years)'); plt.ylabel('Failure to Repay (%)')\n",
    "plt.title('Failure to Repay by Age Group');\n",
    "\n",
    "\n",
    "plot_stats('FLAG_OWN_CAR')\n",
    "plot_stats('FLAG_OWN_REALTY')\n",
    "\n",
    "plot_stats('NAME_FAMILY_STATUS',True, True)\n",
    "\n",
    "\n",
    "\n",
    "plot_stats('OCCUPATION_TYPE',True, False)\n",
    "\n",
    "\n",
    "app_train_domain = app_train.copy()\n",
    "app_test_domain = app_test.copy()\n",
    "\n",
    "app_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\n",
    "app_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']\n",
    "app_train_domain['INCOME_PER_CHILD'] = app_train_domain['AMT_INCOME_TOTAL'] / app_train_domain['CNT_CHILDREN']\n",
    "app_train_domain['HAS_HOUSE_INFORMATION'] = app_train_domain['COMMONAREA_MEDI'].apply(lambda x:1 if x>0 else 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize = (12, 20))\n",
    "# iterate through the new features\n",
    "for i, feature in enumerate(['CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT','INCOME_PER_CHILD']):\n",
    "    \n",
    "    # create a new subplot for each source\n",
    "    plt.subplot(5, 1, i + 1)\n",
    "    # plot repaid loans\n",
    "    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 0, feature], label = 'target == 0')\n",
    "    # plot loans that were not repaid\n",
    "    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 1, feature], label = 'target == 1')\n",
    "    \n",
    "    # Label the plots\n",
    "    plt.title('Distribution of %s by Target Value' % feature)\n",
    "    plt.xlabel('%s' % feature); plt.ylabel('Density');\n",
    "    \n",
    "plt.tight_layout(h_pad = 2.5)\n",
    "\n",
    "def plot_stats(feature,label_rotation=False,horizontal_layout=True):\n",
    "    temp = app_train_domain[feature].value_counts()\n",
    "    df1 = pd.DataFrame({feature: temp.index,'Number of contracts': temp.values})\n",
    "\n",
    "    # Calculate the percentage of target=1 per category value\n",
    "    cat_perc = app_train_domain[[feature, 'TARGET']].groupby([feature],as_index=False).mean()\n",
    "    cat_perc.sort_values(by='TARGET', ascending=False, inplace=True)\n",
    "    \n",
    "    if(horizontal_layout):\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n",
    "    else:\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14))\n",
    "    sns.set_color_codes(\"pastel\")\n",
    "    s = sns.barplot(ax=ax1, x = feature, y=\"Number of contracts\",data=df1)\n",
    "    if(label_rotation):\n",
    "        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    \n",
    "    s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=cat_perc[feature], data=cat_perc)\n",
    "    if(label_rotation):\n",
    "        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    plt.ylabel('Percent of target with value 1 [%]', fontsize=10)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    plt.show();\n",
    "    \n",
    "plot_stats('HAS_HOUSE_INFORMATION',True)\n",
    "\n",
    "\n",
    "\n",
    "app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['CREDIT_TERM'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\n",
    "app_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']\n",
    "app_test_domain['INCOME_PER_CHILD'] = app_test_domain['AMT_INCOME_TOTAL'] / app_test_domain['CNT_CHILDREN']\n",
    "app_test_domain['HAS_HOUSE_INFORMATION'] = app_test_domain['COMMONAREA_MEDI'].apply(lambda x:1 if x>0 else 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "\n",
    "def model(features, test_features, encoding = 'ohe', n_folds = 5):\n",
    "\n",
    "    \n",
    "    #Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "    \n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "    \n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "        \n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "        \n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "    \n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "        \n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        \n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "        \n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "    \n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(n_estimators=1000, objective = 'binary', \n",
    "                                   class_weight = 'balanced', learning_rate = 0.05, \n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, \n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
    "                  early_stopping_rounds = 100, verbose = 200)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, feature_importances, metrics\n",
    "submission, fi, metrics = model(app_train_domain, app_test_domain)\n",
    "print('Baseline metrics')\n",
    "print(metrics)\n",
    "\n",
    "del app_train_domain,app_test_domain\n",
    "gc.collect\n",
    "\n",
    "def plot_feature_importances(df):\n",
    "    \n",
    "    # Sort features according to importance\n",
    "    df = df.sort_values('importance', ascending = False).reset_index()\n",
    "    \n",
    "    # Normalize the feature importances to add up to one\n",
    "    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "\n",
    "    # Make a horizontal bar chart of feature importances\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    # Need to reverse the index to plot most important on top\n",
    "    ax.barh(list(reversed(list(df.index[:15]))), \n",
    "            df['importance_normalized'].head(15), \n",
    "            align = 'center', edgecolor = 'k')\n",
    "    \n",
    "    # Set the yticks and labels\n",
    "    ax.set_yticks(list(reversed(list(df.index[:15]))))\n",
    "    ax.set_yticklabels(df['feature'].head(15))\n",
    "    \n",
    "    # Plot labeling\n",
    "    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "fi_sorted = plot_feature_importances(fi)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
